### Тема 1: GNN и HGNN, их сравнение

| Название | Год | Автор | Ссылка | Краткое содержание |
| :--- | :-- | :--- | :--- | :--- |
| **Hypergraph Neural Networks (HGNN)** | 2019 | Y. Feng, H. You, Z. Zhang, R. Ji, Y. Gao | [Ссылка](https://arxiv.org/abs/1809.09401) | **Основополагающая работа по HGNN.** Предлагает фреймворк для обработки данных на гиперграфах, вводя операцию гиперграфовой свертки для эффективного использования высокоуровневых корреляций. |
| **Semi-Supervised Classification with Graph Convolutional Networks (GCN)** | 2017 | Thomas N. Kipf, Max Welling | [Ссылка](https://arxiv.org/abs/1609.02907) | **Фундаментальная работа по GNN.** Вводит архитектуру графовых сверточных сетей (GCN) — эффективный подход для полуавтоматического обучения на графовых структурах. Является базовой моделью для многих последующих работ. |
| **Inductive Representation Learning on Large Graphs (GraphSAGE)** | 2017 | William L. Hamilton, Rex Ying, Jure Leskovec | [Ссылка](https://arxiv.org/abs/1706.02216) | Представляет **GraphSAGE** — индуктивный фреймворк, который учится генерировать эмбеддинги для ранее не виденных узлов. Вместо обучения отдельных эмбеддингов для каждого узла, он обучает функцию-агрегатор. |
| **Graph Attention Networks (GAT)** | 2018 | Petar Veličković, Guillem Cucurull, et al. | [Ссылка](https://arxiv.org/abs/1710.10903) | Вводит механизм **внимания (attention)** в графовые архитектуры. Это позволяет модели взвешивать важность соседей при агрегации информации, что делает GNN более гибкими и мощными. |
| **Recent Advances in Hypergraph Neural Networks** | 2025 | Murong Yang, Xin-Jian Xu | [Ссылка](https://arxiv.org/abs/2503.07959) | Обзорная статья 2025 года, обобщающая современные достижения в области гиперграфовых нейронных сетей. В статье дана классификация архитектур HGNN на пять типов: гиперграфовые свёрточные сети, гиперграфовые attention-сети, автокодировщики, рекуррентные сети и генеративные модели. Для каждого класса подробно анализируются примеры приложений, математические механизмы и ключевые научные результаты, а также обсуждаются открытые проблемы и перспективные направления исследований
| **DHG-Bench: A Comprehensive Benchmark for Deep Hypergraph Learning** | 2025 | Fan Li, Xiaoyang Wang, Wenjie Zhang, Ying Zhang, Xuemin Lin | [Ссылка](https://arxiv.org/abs/2508.12244) |В статье предлагается DHG-Bench – первый всесторонний бенчмарк для гиперграфовых ННС. Он включает 17 современных моделей HGNN и 22 разнообразных датасета (задачи на уровне узла, гиперребра и всего гиперграфа) под едиными экспериментальными настройками. Авторы исследуют четыре критерия: эффективность (точность), быстродействие, устойчивость к помехам и справедливость (fairness) алгоритмов. Результаты экспериментов выявляют сильные и слабые стороны существующих методов, обеспечивая важные руководящие выводы для будущих разработок.
-----

### Тема 2: HGNN в контексте Geometric Deep Learning

| Название | Год | Автор | Ссылка | Краткое содержание |
| :--- | :-- | :--- | :--- | :--- |
| **Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges** | 2021 | M. M. Bronstein, J. Bruna, T. Cohen, P. Veličković | [Ссылка](https://arxiv.org/abs/2104.13478) | **Фундаментальный обзор** и программа, объединяющая различные архитектуры (CNN, GNN, Transformers) в единую теоретическую framework, основанную на принципах симметрии и инвариантности. |
| **Simplicial Neural Networks** | 2020 | Stefania Ebli, Michaël Defferrard, Gard Spreemann | [Ссылка](https://arxiv.org/abs/2010.03633) | Расширяет GNN на **симплициальные комплексы** — структуры более высокого порядка, чем графы, способные моделировать многосторонние отношения. Гиперграфы являются частным случаем таких комплексов. |
| **Weisfeiler and Leman Go Higher-Order: Message-Passing on Simplicial Complexes** | 2021 | Cristian Bodnar, Fabrizio Frasca, Nina Otter, et al. | [Ссылка](https://arxiv.org/abs/2103.03212) | Обобщает классический тест Вейсфейлера-Лемана (WL) на структуры более высокого порядка, такие как симплициальные комплексы. Это обеспечивает теоретическую основу для **выразительной силы** нейронных сетей на этих структурах. |
| ~одна диссертация будет здесь скоро~ |
-----

### Тема 3: [Гипер]графы знаний и применение в RAG

| Название | Год | Автор | Ссылка | Краткое содержание |
| :--- | :-- | :--- | :--- | :--- |
| **Zep: A Temporal Knowledge Graph Architecture for Agent Memory** | 2025 | Preston Rasmussen, Pavlo Paliychuk, Travis Beauvais, Jack Ryan, Daniel Chalef | [Ссылка](https://arxiv.org/abs/2501.13956) | Представлена система Zep – сервис памяти для LLM-агентов с динамической интеграцией знаний. В её основе лежит компонент Graphiti, который строит темпоральный граф знаний, синтезирующий неструктурированные данные диалогов и структурированные бизнес-данные с учётом временных связей |
| **AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents** | 2024 | Petr Anokhin, Nikita Semenov, et al. | [Ссылка](https://arxiv.org/abs/2407.04363) | Предлагает фреймворк, где LLM-агент **динамически строит и обновляет граф знаний** как внутреннюю "модель мира" для решения задач, используя эпизодическую память. |
| **HyperGraphRAG: Retrieval-Augmented Generation with Hypergraph-Structured Knowledge Representation** | 2025 | Haoran Luo, Haihong E, Guanting Chen, Yandan Zheng, Xiaobao Wu, Yikai Guo, Qika Lin, Yu Feng, Zemin Kuang, Meina Song, Yifan Zhu, Luu Anh Tuan | [Ссылка](https://export.arxiv.org/abs/2503.21322?utm_source=chatgpt.com) |Представлен подход, где RAG (retrieval-augmented generation) расширяется гиперграфной структурой. Основная идея: извлекать n-арные отношения из текстов, строить гиперграф, и при генерации использовать не только текстовые куски, но и гиперребра — факты с несколькими сущностями сразу. Пайплайн: извлечение n-арных отношений → конструирование гиперграфа → стратегия retrieval (для сущностей и гиперребер) → гиперграф-руководимая генерация. |
| **Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks** | 2020 | Patrick Lewis, Ethan Perez, Aleksandara Piktus, et al. | [Ссылка](https://arxiv.org/abs/2005.11401) | **Основополагающая работа по RAG.** Представляет общую архитектуру, которая комбинирует предварительно обученную языковую модель с механизмом извлечения информации из внешней базы знаний (например, Wikipedia). |
| **Knowledge Graphs** | 2021 | Aidan Hogan, Eva Blomqvist, Michael Cochez, et al. | [Ссылка](https://arxiv.org/abs/2003.02320) | **Обширный обзор области графов знаний (KG).** Рассматривает методы их построения, представления (RDF, тройки) и применения, что является необходимой базой для работы с ними. |
| **Modeling Relational Data with Graph Convolutional Networks** | 2018 | Michael Schlichtkrull, Thomas N. Kipf, et al. | [Ссылка](https://arxiv.org/abs/1703.06103) | Одна из первых и ключевых работ по применению **GCN для моделирования графов знаний** (в частности, для предсказания связей). Вводит Relational-GCN (R-GCN). |
| **Unifying Large Language Models and Knowledge Graphs: A Roadmap** | 2024 | Shirley Wu, Guan-Ting Liu, Yu-Chen Lin, et al. | [Ссылка](https://arxiv.org/abs/2306.08302) | **Дорожная карта**, которая систематизирует и описывает три основных парадигмы интеграции LLM и KG: KG-усиленные LLM, LLM-усиленные KG, и синергетические подходы. RAG является частью первой парадигмы. |
| **Retrieval-Augmented Generation with Graphs (GraphRAG)** | 2025 | Haoyu Han, Yu Wang, Harry Shomer, Kai Guo, Jiayuan Ding, Yongjia Lei, Mahantesh Halappanavar, Ryan A. Rossi, Subhabrata Mukherjee, Xianfeng Tang, Qi He, Zhigang Hua, Bo Long, Tong Zhao, Neil Shah, Amin Javari, Yinglong Xia, Jiliang Tang | [Ссылка](https://arxiv.org/abs/2501.00309) | Современный обзор GraphRAG – RAG с использованием графовых структур знаний. Представлена цельная схема GraphRAG, включающая компоненты для обработки запроса, извлечения, организации, генерации и управления источниками данных. Авторы рассматривают методы GraphRAG, адаптированные к различным прикладным областям, и обсуждают ключевые исследовательские задачи и перспективы развития этой технологии |

### Тема 4: Дуальные представления в HGNN

| Название | Год | Автор | Ссылка | Краткое содержание |
| :--- | :-- | :--- | :--- | :--- |
| ~coming soon~ |